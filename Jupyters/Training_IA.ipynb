{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1438dd-64be-430a-b18e-fd68507d1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "import zipfile\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c953d-6c10-4385-9efd-cfe07956bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb36aa4-9218-4619-9888-5176f86c6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conect com google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaec36f-60fd-431c-b762-bd4c59bb481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acessar e descompactar o zip do drive\n",
    "path = \"/content/gdrive/My Drive/Material.zip\"\n",
    "zip_object = zipfile.ZipFile(file = path, mode = \"r\")#r = read\n",
    "zip_object.extractall('./')\n",
    "zip_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47a898-7455-427a-9bc9-157549549907",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imgs = 'Material/fer2013.zip'\n",
    "zip_object = zipfile.ZipFile(file = base_imgs, mode = \"r\")#r = read\n",
    "zip_object.extractall('./')\n",
    "zip_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538db6d-b9b2-4dd2-9f5c-92dce0044f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acessando a base com fotos de expressoes faciais\n",
    "data = pd.read_csv('fer2013/fer2013.csv')\n",
    "#mostra os ultimos resultados do csv\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201081b5-eb0a-41be-b689-0e112dd8586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(data['emotion'], bins = 30)\n",
    "plt.title('Imagnes x emoções')\n",
    "#Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9b167-0023-4f92-9de0-c2963812421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist()\n",
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5ff13-2c88-4368-baf7-aca258c61bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "largura, altura = 48, 48\n",
    "faces = []\n",
    "amostras = 0\n",
    "#formato de lista para numpy array\n",
    "for pixel_sequence in pixels:\n",
    "  face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "  face = np.asarray(face).reshape(largura, altura)\n",
    "  faces.append(face)\n",
    "\n",
    "  if (amostras < 10):\n",
    "    cv2_imshow(face)\n",
    "  amostras += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ee3fc-836f-443c-a3bf-2d09a29bf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Numero total de imagens do dataset: ', str(len(faces)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02614ccf-860e-46fb-842d-878e7daf7948",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25446932-3ef9-4cd5-895e-49cc3fee1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qtd de imagens largura e altura\n",
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fcbd3-28cf-447d-a7c7-4abfbb9f4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens com esaca de cinza adicionada no final\n",
    "#quando coloca o -1 quer dizer que vai adiconar uma nova dimensão no final do vetor da matriz\n",
    "faces = np.expand_dims(faces, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861dbf6-c2a1-4fe8-b95b-9f3c80d2074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f342d-8050-4c97-bd39-6a586f1dd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = normalizar(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62882f1-9578-43cc-982e-59694db1be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970869e5-8038-4440-8031-1d2827423344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar emoção\n",
    "emocoes = pd.get_dummies(data['emotion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647d8db-5185-4723-9114-19c21342cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disgust neste caso\n",
    "#essa rede neural tera 7 neuronios na camada de saida que ele ira indicar uma probabilidade de ele pertencer a cada uma dessas faces\n",
    "emocoes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014dbe4d-c806-421b-bb3d-51c8e3a22829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f558096-e225-49f1-aa63-3fe95a3ae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir em conjuntos para treinameto e validação\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces, emocoes, test_size = 0.1, random_state = 42)\n",
    "_, X_val, _, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535b5d5-0702-4875-98a1-2b12bf37832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Numero de imagnes no conjunto de treinamento: ', len(X_train))\n",
    "print('Numero de imagnes no conjunto de teste: ', len(X_test))\n",
    "print('Numero de imagnes no conjunto de validação: ', len(X_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
